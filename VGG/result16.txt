Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz
100%|██████████| 9912422/9912422 [00:00<00:00, 68569331.35it/s]
Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz
100%|██████████| 28881/28881 [00:00<00:00, 12426722.80it/s]
Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz
100%|██████████| 1648877/1648877 [00:00<00:00, 28362415.50it/s]Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw


Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz
100%|██████████| 4542/4542 [00:00<00:00, 21648328.15it/s]
Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 64, 64]             640
            Conv2d-2           [-1, 64, 64, 64]          36,928
         MaxPool2d-3           [-1, 64, 32, 32]               0
              ReLU-4           [-1, 64, 32, 32]               0
            Conv2d-5          [-1, 128, 32, 32]          73,856
            Conv2d-6          [-1, 128, 32, 32]         147,584
         MaxPool2d-7          [-1, 128, 16, 16]               0
              ReLU-8          [-1, 128, 16, 16]               0
            Conv2d-9          [-1, 256, 16, 16]         295,168
           Conv2d-10          [-1, 256, 16, 16]         590,080
           Conv2d-11          [-1, 256, 16, 16]         590,080
        MaxPool2d-12            [-1, 256, 8, 8]               0
             ReLU-13            [-1, 256, 8, 8]               0
           Conv2d-14            [-1, 512, 8, 8]       1,180,160
           Conv2d-15            [-1, 512, 8, 8]       2,359,808
           Conv2d-16            [-1, 512, 8, 8]       2,359,808
        MaxPool2d-17            [-1, 512, 4, 4]               0
             ReLU-18            [-1, 512, 4, 4]               0
           Conv2d-19            [-1, 512, 4, 4]       2,359,808
           Conv2d-20            [-1, 512, 4, 4]       2,359,808
           Conv2d-21            [-1, 512, 4, 4]       2,359,808
        MaxPool2d-22            [-1, 512, 2, 2]               0
             ReLU-23            [-1, 512, 2, 2]               0
           Linear-24                 [-1, 1024]       2,098,176
             ReLU-25                 [-1, 1024]               0
           Linear-26                  [-1, 512]         524,800
             ReLU-27                  [-1, 512]               0
           Linear-28                   [-1, 10]           5,130
================================================================
Total params: 17,341,642
Trainable params: 17,341,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 10.37
Params size (MB): 66.15
Estimated Total Size (MB): 76.54
----------------------------------------------------------------
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[1/20] Train Loss: 0.2701, Train Acc: 0.9114

[1/20] Test Loss: 0.0589, Test Acc: 0.9821

[2/20] Train Loss: 0.0802, Train Acc: 0.9762

[2/20] Test Loss: 0.0681, Test Acc: 0.9783

[3/20] Train Loss: 0.0616, Train Acc: 0.9822

[3/20] Test Loss: 0.0702, Test Acc: 0.9801

[4/20] Train Loss: 0.0537, Train Acc: 0.9845

[4/20] Test Loss: 0.0295, Test Acc: 0.9897

[5/20] Train Loss: 0.0444, Train Acc: 0.9873

[5/20] Test Loss: 0.0405, Test Acc: 0.9865

[6/20] Train Loss: 0.0395, Train Acc: 0.9888

[6/20] Test Loss: 0.0408, Test Acc: 0.9878

[7/20] Train Loss: 0.0334, Train Acc: 0.9900

[7/20] Test Loss: 0.0412, Test Acc: 0.9869

[8/20] Train Loss: 0.0335, Train Acc: 0.9900

[8/20] Test Loss: 0.0457, Test Acc: 0.9881

[9/20] Train Loss: 0.0307, Train Acc: 0.9916

[9/20] Test Loss: 0.0331, Test Acc: 0.9897

[10/20] Train Loss: 0.0256, Train Acc: 0.9929

[10/20] Test Loss: 0.0406, Test Acc: 0.9897

[11/20] Train Loss: 0.0271, Train Acc: 0.9924

[11/20] Test Loss: 0.0293, Test Acc: 0.9904

[12/20] Train Loss: 0.0239, Train Acc: 0.9932

[12/20] Test Loss: 0.0310, Test Acc: 0.9885

[13/20] Train Loss: 0.0231, Train Acc: 0.9936

[13/20] Test Loss: 0.0334, Test Acc: 0.9885

[14/20] Train Loss: 0.0221, Train Acc: 0.9938

[14/20] Test Loss: 0.0284, Test Acc: 0.9904

[15/20] Train Loss: 0.0216, Train Acc: 0.9939

[15/20] Test Loss: 0.0461, Test Acc: 0.9884

[16/20] Train Loss: 0.0185, Train Acc: 0.9951

[16/20] Test Loss: 0.0254, Test Acc: 0.9919

[17/20] Train Loss: 0.0236, Train Acc: 0.9935

[17/20] Test Loss: 0.0351, Test Acc: 0.9911

[18/20] Train Loss: 0.0161, Train Acc: 0.9955

[18/20] Test Loss: 0.0268, Test Acc: 0.9915

[19/20] Train Loss: 0.0199, Train Acc: 0.9944

[19/20] Test Loss: 0.0336, Test Acc: 0.9923

[20/20] Train Loss: 0.0184, Train Acc: 0.9949

[20/20] Test Loss: 0.0392, Test Acc: 0.9872